{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().run_line_magic('load_ext', 'autoreload')\n",
    "get_ipython().run_line_magic('autoreload', '2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,\"./../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from pypdf import PdfReader\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/nelsonlin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"../documents/GIS+Prospectus+UK.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_reader = PdfReader(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_page_parse_dict_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split document to list of pages\n",
    "for page_num, page in enumerate(pdf_reader.pages):\n",
    "     text = page.extract_text()\n",
    "     pdf_page_parse_dict = {}\n",
    "     pdf_page_parse_dict['page_num'] = page_num\n",
    "     pdf_page_parse_dict['text'] = text\n",
    "     pdf_page_parse_dict_list.append(pdf_page_parse_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf_page_parse_dict_list[96]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_page  = pd.DataFrame(pdf_page_parse_dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/882 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 882/882 [00:00<00:00, 2990.45it/s]\n"
     ]
    }
   ],
   "source": [
    "# split pages to sentences\n",
    "pdf_sentence_dict_list =[]\n",
    "for page_dict in  tqdm(pdf_page_parse_dict_list):\n",
    "     page_num = page_dict['page_num']\n",
    "     text = page_dict['text']\n",
    "\n",
    "     blob = TextBlob(text)\n",
    "     for index,sentence in enumerate(blob.sentences):\n",
    "          sentence_dict = {}\n",
    "          sentence_dict['page_num'] = page_num\n",
    "          sentence_dict['sentence_index'] = index\n",
    "          sentence_dict['sentence'] = str(sentence)\n",
    "          pdf_sentence_dict_list.append(sentence_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentence  = pd.DataFrame(pdf_sentence_dict_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Function Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fund_name(text):\n",
    "    import re\n",
    "    \n",
    "    text = text.replace(\"\\n\",\"\")\n",
    "    pattern = r'\\b(?:[^a-zA-Z]*([A-Z][a-zA-Z ]+Fund)[^a-zA-Z]*)\\b'\n",
    "    matches = re.findall(pattern, text)\n",
    "\n",
    "    filters = []\n",
    "    for name in matches:\n",
    "        if \"  \" in name:\n",
    "            #  skip if more than two continuous space\n",
    "            continue\n",
    "        # all words should be uppercase at the first letter\n",
    "        if name == \" \".join([w.capitalize() for w  in name.split(\" \")]):\n",
    "            # split more funds if the extracted name contains more \"Fund\"\n",
    "            filters.extend([n.lstrip() + \"Fund\" for n in name.split(\"Fund\")])\n",
    "\n",
    "    return filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = pdf_page_parse_dict_list[96]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract_fund_name(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentence['fund_names'] = df_sentence['sentence'].apply(extract_fund_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_names = []\n",
    "for names in df_sentence[df_sentence['fund_names'].apply(lambda x: len(x)!=0)]['fund_names']:\n",
    "    all_names.extend(names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_names = list(set(all_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_names.sort(key = lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Merge short fund name to long fun name: \n",
    "#  For Example: \"Market Bond Fund\" should belong to \"Global Market Bond Fund\"  \n",
    "merged_names = all_names.copy() \n",
    "for (index,name) in enumerate(all_names):\n",
    "    for next_name in all_names[index+1:]:\n",
    "        if name in next_name:\n",
    "            all_names[index]=\"\"\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_names =  [name for name in all_names if name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Stop Fund Names;\n",
    "#  For example: \"This Fund\", \"A Fund\",\"Mty Fund\" should not be eligible\n",
    "stop_fund_names = set(word.capitalize() + \" Fund\"  for word in stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_names =  [name for name in all_names if name not in stop_fund_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Term Fund',\n",
       " 'Asset Fund',\n",
       " 'Selected Fund',\n",
       " 'Original Fund',\n",
       " 'Reporting Fund',\n",
       " 'Euro Bond Fund',\n",
       " 'Underlying Fund',\n",
       " 'Euro Credit Fund',\n",
       " 'Call Risk A Fund',\n",
       " 'Global Bond Fund',\n",
       " 'Dynamic Bond Fund',\n",
       " 'State Street Fund',\n",
       " 'Long Duration Fund',\n",
       " 'Mortgage Risk A Fund',\n",
       " 'Euro Income Bond Fund',\n",
       " 'Arbitrage Risk A Fund',\n",
       " 'Strategic Income Fund',\n",
       " 'Global Advantage Fund',\n",
       " 'Commodity Risk A Fund',\n",
       " 'Irish Real Estate Fund',\n",
       " 'Total Return Bond Fund',\n",
       " 'Diversified Income Fund',\n",
       " 'Term Opportunities Fund',\n",
       " 'Currency Hedging A Fund',\n",
       " 'Real Estate Risk A Fund',\n",
       " 'Global Real Return Fund',\n",
       " 'Emerging Local Bond Fund',\n",
       " 'Term Local Currency Fund',\n",
       " 'Low Duration Income Fund',\n",
       " 'Low Average Duration Fund',\n",
       " 'Factor Europe Equity Fund',\n",
       " 'Energy Infrastructure Fund',\n",
       " 'Emerging Markets Bond Fund',\n",
       " 'Commodity Real Return Fund',\n",
       " 'International Monetary Fund',\n",
       " 'Global High Yield Bond Fund',\n",
       " 'Mortgage Opportunities Fund',\n",
       " 'National Pension Reserve Fund',\n",
       " 'Euro Long Average Duration Fund',\n",
       " 'Low Duration Opportunities Fund',\n",
       " 'Asia Strategic Interest Bond Fund',\n",
       " 'Global Advantage Real Return Fund',\n",
       " 'Emerging Markets Corporate Bond Fund',\n",
       " 'Global Low Duration Real Return Fund',\n",
       " 'Diversified Income Duration Hedged Fund',\n",
       " 'Low Duration Global Investment Grade Credit Fund']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  All qualified fund name\n",
    "all_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
